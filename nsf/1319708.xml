<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: MicSynth: Enhancing and Reconstructing Sound Scenes from Crowdsourced Recordings</AwardTitle>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>06/30/2018</AwardExpirationDate>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
</ProgramOfficer>
<AbstractNarration>There is no doubt that we live in an environment that is massively recorded by multiple people at any point in time. Although we have the technology to combine such information in the visual space (e.g., with PhotoSynth), there is currently no good way to combine audio streams from multiple recordings of the same event. This projects fills that gap by developing new techniques in spectral decompositions and landmark-based localization methods to support taking large amounts of low-level audio recordings of the same event and resynthesize them as one high-quality version, eliminating the artifacts and noise of each individual recording while taking advantage of their strong points.&lt;br/&gt;&lt;br/&gt;This project aims to introduce new computational tools to combine uncurated recordings at a large scale, and produce information that no single recording can provide. Combining all available information and producing objective representations will enable effective sifting through data from massively recorded events (e.g., social unrest, natural disasters, historical moments) and focus on the needed information. The resulting tools will support creation of high-quality recordings from historical events that might not otherwise be well documented, by using the power of the crowds. The project web site (http://www.cs.illinois.edu/~paris/crowdmic) will provide access to the research results, including a service that allows the consolidation from user-submitted recordings, publication and source code in order to to stimulate activity in this field. Research results will also be incorporated in the development of classes on social and crowdsourcing aspects of audio and signal processing.</AbstractNarration>
<MinAmdLetterDate>09/05/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/05/2013</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1319708</AwardID>
<Investigator>
<FirstName>Paris</FirstName>
<LastName>Smaragdis</LastName>
<EmailAddress>paris@illinois.edu</EmailAddress>
<StartDate>09/05/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>CHAMPAIGN</CityName>
<ZipCode>618207473</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>SUITE A</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
</Institution>
<ProgramElement>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramElement>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
