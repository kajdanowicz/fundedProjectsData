<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Socially Assistive Robots</AwardTitle>
<AwardEffectiveDate>04/01/2012</AwardEffectiveDate>
<AwardExpirationDate>03/31/2019</AwardExpirationDate>
<AwardAmount>1340840</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim P. Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Socially Assistive Robots&lt;br/&gt;Lead PI/Institution: Brian Scassellati, Yale University&lt;br/&gt;This Expedition will develop the fundamental computational techniques that will enable the design, implementation, and evaluation of robots that encourage social, emotional, and cognitive growth in children, including those with social or cognitive deficits.  The need for this technology is driven by critical societal problems that require sustained, personalized support that supplements the efforts of educators, parents, and clinicians.   For example, clinicians and families struggle to provide individualized educational services to children with social and cognitive deficits, whose numbers have quadrupled in the US in the last decade alone.  In many schools, educators struggle to provide language instruction for children raised in homes where a language other than English is spoken (over 20%), the fastest-growing segment of the school-age population.  This Expedition aims to support the individual needs of these children with socially assistive robots that help to guide the children toward long-term behavioral goals, that are customized to the particular needs of each child, and that develop and change as the child does.  &lt;br/&gt;To achieve this vision, this Expedition will advance the state-of-the-art in socially assistive human-robot interaction from short-term interactions in structured environments to long-term interactions that are adaptive, engaging, and effective. This progress will require transformative computing research in three broad and naturally interrelated research areas. First, the Expedition will develop computational models of the dynamics of social interaction, so that robots can automatically detect, analyze, and influence agency, intention, and other social interaction primitives in dynamic environments. Second, the Expedition will develop machine learning algorithms that adapt and personalize interactions to individual physical, social, and cognitive differences, enabling robots to teach and shape behavior in ways that are tailored to the needs, preferences, and capabilities of each individual. Third, the Expedition will develop systems that guide children toward specific learning goals over periods of weeks and months, allowing for truly long-term guidance and support. Research in these three areas will be integrated into socially assistive robots that are deployed in schools and homes for durations of up to one year.  &lt;br/&gt;This Expedition has the potential to substantially impact the effectiveness of education and healthcare for children, and the technological tools developed will serve as the basis for enhancing the lives of children and other groups that require specialized support and intervention. The proposed computing research is tied to a comprehensive student training program, bringing a compelling, engaging, and grounded STEM experience to K-12 students through in-school and after-school activities. It also establishes an annual training summit to provide undergraduates with the multi-disciplinary background to engage in this promising research area in graduate school. Finally, by establishing a brand name for socially assistive robotics, this effort will create a central authority for the distribution of high-quality, peer-reviewed information, providing a coherent focal point for enhancing outreach and education.&lt;br/&gt;For more information visit www.yale.edu/SAR</AbstractNarration>
<MinAmdLetterDate>04/02/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/10/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1139161</AwardID>
<Investigator>
<FirstName>Clifford</FirstName>
<LastName>Nass</LastName>
<EmailAddress>nass@stanford.edu</EmailAddress>
<StartDate>04/02/2012</StartDate>
<EndDate>07/31/2014</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Schwartz</LastName>
<EmailAddress>daniel.schwartz@stanford.edu</EmailAddress>
<StartDate>04/02/2012</StartDate>
<EndDate>10/29/2014</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Pamela</FirstName>
<LastName>Hinds</LastName>
<EmailAddress>phinds@stanford.edu</EmailAddress>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Palo Alto</CityName>
<ZipCode>943041212</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>3160 Porter Drive</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>1640</Code>
<Text>INFORMATION TECHNOLOGY RESEARC</Text>
</ProgramElement>
<ProgramElement>
<Code>7367</Code>
<Text>Cyber-Human Systems (CHS)</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramElement>
<Code>7723</Code>
<Text>EXPERIMENTAL EXPEDITIONS</Text>
</ProgramElement>
<ProgramReference>
<Code>1640</Code>
<Text>INFORMATION TECHNOLOGY RESEARC</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7723</Code>
<Text>EXPERIMENTAL EXPEDITIONS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
</ProgramReference>
</Award>
</rootTag>
