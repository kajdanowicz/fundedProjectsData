<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>MRI Development: Enabling Research in Natural Communication with Virtual Tutors, Therapists, and Robotic Companions</AwardTitle>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardAmount>1348000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rita V. Rodriguez</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project, developing SocioBot-SDS (SocioBot-Spoken Dialog System), an instrument in the form of a robotic character with an emotional response, is expected to advance research involving next generation human-machine interactions. The robotic instrument will be used for therapeutic and educational purposes. Its development will specifically contribute to the research area of perceived speech and visual behaviors. The components of the instrument integrate a unique level of programmability and robustness to the display of human- and non-human-like emotive gestures with conventional orientation control through an articulated neck. The work is expected to accelerate research and development of social robots that can accurately model the dynamics of face-to-face communication with a sensitive and effective human tutor, clinician, or caregiver to a degree unachievable with current instrumentation. The robotic agent builds on advances in computer vision, spoken dialogue systems, character animation and effective computing to conduct dialogues that establish rapport with users producing rich, emotive facial gestures synchronized with prosodic speech generations in response to users' speech and emotions. The instrument represents a new level of integration of emotive capabilities that enable researchers to study socially emotive/robots/agents that can understand spoken language and show emotions and interact, speak, and communicate effectively with people in a natural way (as humans do).&lt;br/&gt;&lt;br/&gt;The instrument provides an exciting platform for research and training supporting cross-discipline technology. Since the research community would have access to the instrument, research in how to optimize communication among people and avatars might be accelerated through the perception of speech patterns and visual behaviors of those interacting. The instrument represents a new level of integration of emotive capabilities and serves as a platform for designing a new generation of more immersive and effective intelligent tutoring and therapy systems, and robot-assisted therapeutic treatments for human disabilities that include infants at risk for sensory, attention and language delays, as well as adults with mental disabilities.  From an educational perspective, the proposed activities will enhance inter-disciplinary education by involving students at all levels, during and beyond the development of the instrument. The resulting instrument will be freely distributed for researchers to investigate robotic behaviors that lead to immersive and effective applications across a variety of task domains such as teaching students to read, tutoring students in science, conducting speech and language therapy sessions, or providing companionship to elderly individuals in their homes. Moreover, the activities initiated by this development enhance interdisciplinary education, involving students at the undergraduate and graduate levels, during and beyond the development of the instrument.</AbstractNarration>
<MinAmdLetterDate>08/20/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/11/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1427872</AwardID>
<Investigator>
<FirstName>Wayne</FirstName>
<LastName>Ward</LastName>
<EmailAddress>wward@bltek.com</EmailAddress>
<StartDate>08/20/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ronald</FirstName>
<LastName>Cole</LastName>
<EmailAddress>rcole@bltek.com</EmailAddress>
<StartDate>08/20/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mohammad</FirstName>
<LastName>Mahoor</LastName>
<EmailAddress>mmahoor@du.edu</EmailAddress>
<StartDate>08/20/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Juan</FirstName>
<LastName>Wachs</LastName>
<EmailAddress>jpwachs@purdue.edu</EmailAddress>
<StartDate>08/20/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Denver</Name>
<CityName>Denver</CityName>
<ZipCode>802104711</ZipCode>
<PhoneNumber>3038712000</PhoneNumber>
<StreetAddress>2199 S. University Blvd.</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
</Institution>
<ProgramElement>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramElement>
<ProgramElement>
<Code>1640</Code>
<Text>INFORMATION TECHNOLOGY RESEARC</Text>
</ProgramElement>
<ProgramElement>
<Code>1714</Code>
<Text>SPECIAL PROJECTS - CISE</Text>
</ProgramElement>
<ProgramElement>
<Code>7367</Code>
<Text>Cyber-Human Systems (CHS)</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramElement>
<Code>8013</Code>
<Text>National Robotics Initiative</Text>
</ProgramElement>
<ProgramReference>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
</ProgramReference>
</Award>
</rootTag>
