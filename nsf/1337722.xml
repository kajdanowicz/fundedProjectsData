<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>MRI: Development of Large-Scale Dense Scene Capture and Tracking Instrument</AwardTitle>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rita V. Rodriguez</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Proposal #: 13-37899&lt;br/&gt;PI(s):  Hahn, James K.&lt;br/&gt;  Lee, Taeyoung; Philbeck, John W.; Rickmond, Brian G.; Townsend, Gabe Sibley&lt;br/&gt;Institution: George Washington University &lt;br/&gt;Title:   MRI/Dev.: Large-Scale Dense Scene Capture and Tracking Instrument&lt;br/&gt;Project Proposed:&lt;br/&gt;This project, developing a large-scale, dense 3D measurement instrument for capturing dynamic environments, integrates devices such as range-and-color sensing devices like depth cameras (RGB-D sensors) by designing and developing key technical methodologies to fuse the data received from remote networked sensors. The instrument will collectively cover a large space at a sampling resolution of at least 1cm with submillimeter resolution in localized regions. These data are then fused into a single underlying representation. The work involves developing a system that possesses both large-scale and real-time dense capture capabilities. Specifically, &lt;br/&gt;- Experimentally validating perception, planning and control algorithms of agile mobile robots (particularly those that operate with deformable objects) requires ground truth representation of those environments.&lt;br/&gt;- Validating computational tools for tether dynamics and control for flexible multibody systems requires the capture of their environment in a large environment.&lt;br/&gt;- Study of human motion for biomechanics, physical therapy, and exercise science applications requires accurate capture of dynamically changing deformable human shapes in a large environment.&lt;br/&gt;- Image-guided surgical procedures require capture of localized dense patient anatomical surface registered in a larger surgical environment.&lt;br/&gt;- Human visual perception and navigation require a dense model of the surrounding environments that include object in motion, thus advancing the state of eye movement analysis by enabling fast, automated and objective coding of object analysis by enabling fast, automated, and objective coding of objects people see as they move through the environment.&lt;br/&gt;- The study of foot deformations enabled by dense shape capture during running and walking on real sediments will shed light on the evolution of gait and human anatomy, and the biomechanics of barefoot walking and running. &lt;br/&gt;Thus, facilitating new research, the developed system enables rapid capture and construction of large dynamic high-resolution virtual environments that duplicate specific real-world environments, including deformable objects, with unprecedented density of detail.</AbstractNarration>
<MinAmdLetterDate>08/15/2013</MinAmdLetterDate>
<MaxAmdLetterDate>03/09/2016</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1337722</AwardID>
<Investigator>
<FirstName>Gabriel</FirstName>
<LastName>Sibley</LastName>
<EmailAddress>gsibley@colorado.edu</EmailAddress>
<StartDate>08/15/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>James</FirstName>
<LastName>Hahn</LastName>
<EmailAddress>hahn@gwu.edu</EmailAddress>
<StartDate>08/15/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>John</FirstName>
<LastName>Philbeck</LastName>
<EmailAddress>philbeck@gwu.edu</EmailAddress>
<StartDate>08/15/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Sergio</FirstName>
<LastName>Almecija</LastName>
<EmailAddress>sergio.almecija@gmail.com</EmailAddress>
<StartDate>03/09/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Taeyoung</FirstName>
<LastName>Lee</LastName>
<EmailAddress>tylee@gwu.edu</EmailAddress>
<StartDate>08/15/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Brian</FirstName>
<LastName>Richmond</LastName>
<EmailAddress>brian.richmond@gmail.com</EmailAddress>
<StartDate>08/15/2013</StartDate>
<EndDate>03/09/2016</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>George Washington University</Name>
<CityName>Washington</CityName>
<ZipCode>200522000</ZipCode>
<PhoneNumber>2029946255</PhoneNumber>
<StreetAddress>2121 Eye Street NW</StreetAddress>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<StateCode>DC</StateCode>
</Institution>
<ProgramElement>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramElement>
<ProgramReference>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramReference>
</Award>
</rootTag>
